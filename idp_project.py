# -*- coding: utf-8 -*-
"""idp project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dPN7jafXpZSKCpcWsfcP9plip0aLnzjv
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from tensorflow.keras.preprocessing import image_dataset_from_directory
from keras.models import Sequential
from sklearn.metrics import confusion_matrix
from keras.layers import Conv2D,MaxPooling2D,Dropout,Dense,Flatten,BatchNormalization,Rescaling
from keras.datasets import mnist
from keras.losses import sparse_categorical_crossentropy
from keras.optimizers import Adam,SGD
from keras.callbacks import EarlyStopping
from tensorflow.keras.utils import to_categorical,load_img,array_to_img
import numpy as np
from matplotlib import pyplot as plt
from keras import Model
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

import cv2
from PIL import Image

from keras import layers
from tensorflow.keras import applications
from keras.applications import MobileNetV2
from keras.callbacks import Callback, ModelCheckpoint
# The ImageDataGenerator class has been moved to tensorflow.keras.preprocessing.image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.optimizers import Adam
import tensorflow as tf

from sklearn.model_selection import train_test_split
from sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix,classification_report

from tqdm import tqdm

from google.colab import drive
drive.mount('/content/drive')

train_df = pd.read_csv('/content/drive/MyDrive/aptos 2019/train_1.csv')
test_df = pd.read_csv('/content/drive/MyDrive/aptos 2019/test.csv')
valid_df=pd.read_csv('/content/drive/MyDrive/aptos 2019/valid.csv')
print(train_df.shape)
print(test_df.shape)
print(test_df.head())
train_df.columns

train_df['diagnosis'].value_counts()
train_df['diagnosis'].hist()

columns=4
rows=3
fig=plt.figure(figsize=(5*columns, 4*rows))
for i in range(columns*rows):
      image_path = train_df.loc[i,'id_code']
      image_id = train_df.loc[i,'diagnosis']
      img = cv2.imread(f'/content/drive/MyDrive/aptos 2019/train_images/train_images/{image_path}.png')
      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
      fig.add_subplot(rows, columns, i+1)
      plt.title(image_id)
      plt.imshow(img)
plt.tight_layout()

columns=4
rows=3
fig=plt.figure(figsize=(5*columns, 4*rows))
for i in range(columns*rows):
      image_path = test_df.loc[i,'id_code']
      image_id = test_df.loc[i,'diagnosis']
      img = cv2.imread(f'/content/drive/MyDrive/aptos 2019/test_images/test_images/{image_path}.png')
      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
      fig.add_subplot(rows, columns, i+1)
      plt.title(image_id)
      plt.imshow(img)
plt.tight_layout()

def preprocess_image(image_path, desired_size=224):
    im = Image.open(image_path)
    im = im.resize((desired_size, )*2, resample=Image.BILINEAR)

    return im
N = test_df.shape[0]
x_val = np.empty((N, 224, 224, 3), dtype=np.float32)

for i, image_id in enumerate(tqdm(test_df['id_code'])):#/content/drive/MyDrive/aptos 2019/test_images/test_images/e4dcca36ceb4.png
    x_val[i, :, :, :] = preprocess_image(
        f'/content/drive/MyDrive/aptos 2019/test_images/test_images/{image_id}.png'
    )

np.save(f'/content/drive/MyDrive/aptos 2019/x_val',x_val)

def preprocess_image(image_path, desired_size=224):
    im = Image.open(image_path)
    im = im.resize((desired_size, )*2, resample=Image.BILINEAR)

    return im

N = train_df.shape[0]
x_train = np.empty((N, 224, 224, 3), dtype=np.float32)

for i, image_id in enumerate(tqdm(train_df['id_code'])):
  x_train[i, :, :, :] = preprocess_image(
                        f'/content/drive/MyDrive/aptos 2019/train_images/train_images/{image_id}.png')

np.save(f'/content/drive/MyDrive/aptos 2019/x_train',x_train)

def preprocess_image(image_path, desired_size=224):
    im = Image.open(image_path)
    im = im.resize((desired_size, )*2, resample=Image.BILINEAR)

    return im
N = test_df.shape[0]
x_valid = np.empty((N, 224, 224, 3), dtype=np.float32)

for i, image_id in enumerate(tqdm(valid_df['id_code'])):#/content/drive/MyDrive/aptos 2019/test_images/test_images/e4dcca36ceb4.png
    x_valid[i, :, :, :] = preprocess_image(
        f'/content/drive/MyDrive/aptos 2019/val_images/val_images/{image_id}.png'
    )

np.save(f'/content/drive/MyDrive/aptos 2019/x_valid',x_valid)

x_train=np.load(f'/content/drive/MyDrive/aptos 2019/x_train.npy')

x_val=np.load(f'/content/drive/MyDrive/aptos 2019/x_val.npy')

x_valid=np.load(f'/content/drive/MyDrive/aptos 2019/x_valid.npy')

y_train = train_df['diagnosis']
y_val = test_df['diagnosis']
y_valid=valid_df['diagnosis']
#print(x_train.shape)
print(y_train.shape)
#print(x_val.shape)
print(y_val.shape)
print(y_valid.shape)



from tensorflow.keras.applications import VGG19
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load VGG19 base model
base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Extract features using VGG19
train_features = base_model.predict(x_train)
val_features = base_model.predict(x_val)

# Flatten or reshape the features
train_features_flat = train_features.reshape(train_features.shape[0], -1)
val_features_flat = val_features.reshape(val_features.shape[0], -1)

# Train Random Forest classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(train_features_flat, y_train)

# Predict on validation set
val_predictions = clf.predict(val_features_flat)

# Evaluate the model
val_accuracy = accuracy_score(y_val, val_predictions)
print(f'Validation Accuracy: {val_accuracy}')
print(classification_report(y_val, val_predictions))
print(confusion_matrix(y_val, val_predictions))



BATCH_SIZE=32
from keras.applications import VGG19
base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze all layers in the base model
for layer in base_model.layers:
    layer.trainable = False

# Add custom classification head
x = base_model.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
predictions = tf.keras.layers.Dense(5, activation='softmax')(x)  # assuming 2 classes (e.g., diabetic vs. non-diabetic)
model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)
model.compile(
        loss='sparse_categorical_crossentropy',
        optimizer='adam',
        metrics=['accuracy'])
BATCH_SIZE=32
from keras.applications import VGG19
import tensorflow as tf
base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze all layers in the base model
for layer in base_model.layers:
    layer.trainable = False

# Add custom classification head
x = base_model.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
predictions = tf.keras.layers.Dense(5, activation='softmax')(x)  # assuming 2 classes (e.g., diabetic vs. non-diabetic)
model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)
model.compile(
        loss='sparse_categorical_crossentropy',
        optimizer='adam',
        metrics=['accuracy'])
history = model.fit(
    x_train,y_train,
    steps_per_epoch=x_train.shape[0] // BATCH_SIZE, #Corrected this line
    epochs=10,
    validation_data=(x_val, y_val)
)

model.evaluate(x_valid,y_valid)

BATCH_SIZE=32
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze all layers in the base model
for layer in base_model.layers:
    layer.trainable = False

# Add custom classification head
x = base_model.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
predictions = tf.keras.layers.Dense(5, activation='softmax')(x)  # assuming 2 classes (e.g., diabetic vs. non-diabetic)
model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)
model.compile(
        loss='sparse_categorical_crossentropy',
        optimizer='adam',
        metrics=['accuracy'])
h1 = model.fit(
    x_train,y_train,
    # Use integer division (//) to ensure steps_per_epoch is an integer
    steps_per_epoch=x_train.shape[0] // BATCH_SIZE,
    batch_size=BATCH_SIZE,
    epochs=10,
    validation_data=(x_val, y_val)
)

model.evaluate(x_valid,y_valid)

BATCH_SIZE = 32
import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze all layers in the base model
for layer in base_model.layers:
    layer.trainable = False

# Add custom classification head
x = base_model.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
predictions = tf.keras.layers.Dense(5, activation='softmax')(x)  # assuming 5 classes
model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)
model.compile(
        loss='sparse_categorical_crossentropy',
        optimizer='adam',
        metrics=['accuracy'])
h1 = model.fit(
    x_train,y_train,
    # Use floor division (//) to ensure steps_per_epoch is an integer
    steps_per_epoch=x_train.shape[0] // BATCH_SIZE,
    batch_size=BATCH_SIZE,
    epochs=10,
    validation_data=(x_val, y_val)
)

model.evaluate(x_valid,y_valid)

BATCH_SIZE = 32
import tensorflow as tf
from tensorflow.keras.applications import Xception
base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze all layers in the base model
for layer in base_model.layers:
    layer.trainable = False

# Add custom classification head
x = base_model.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
predictions = tf.keras.layers.Dense(5, activation='softmax')(x)  # assuming 5 classes
model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)
model.compile(
        loss='sparse_categorical_crossentropy',
        optimizer='adam',
        metrics=['accuracy'])
h1 = model.fit(
    x_train,y_train,
    batch_size=BATCH_SIZE,
    epochs=10,
    validation_data=(x_val, y_val)
)

model.evaluate(x_valid,y_valid)

BATCH_SIZE = 32
import tensorflow as tf
from tensorflow.keras.applications import InceptionResNetV2
base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze all layers in the base model
for layer in base_model.layers:
    layer.trainable = False

# Add custom classification head
x = base_model.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
x = tf.keras.layers.Dense(128, activation='relu')(x)
predictions = tf.keras.layers.Dense(5, activation='softmax')(x)  # assuming 5 classes
model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)
model.compile(
        loss='sparse_categorical_crossentropy',
        optimizer='adam',
        metrics=['accuracy'])
h1 = model.fit(
    x_train,y_train,
    batch_size=BATCH_SIZE,
    epochs=10,
    validation_data=(x_val, y_val)
)

model.evaluate(x_valid,y_valid)

from tensorflow.keras.applications import VGG19
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load VGG19 base model
base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Extract features using VGG19
train_features = base_model.predict(x_train)
val_features = base_model.predict(x_val)

# Flatten or reshape the features
train_features_flat = train_features.reshape(train_features.shape[0], -1)
val_features_flat = val_features.reshape(val_features.shape[0], -1)

# Train Random Forest classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(train_features_flat, y_train)

# Predict on validation set
val_predictions = clf.predict(val_features_flat)

# Evaluate the model
val_accuracy = accuracy_score(y_val, val_predictions)
print(f'Validation Accuracy: {val_accuracy}')
print(classification_report(y_val, val_predictions))
print(confusion_matrix(y_val, val_predictions))

valid_features= base_model.predict(x_valid)
valid_features_flat = valid_features.reshape(valid_features.shape[0], -1)
valid_predictions = clf.predict(valid_features_flat)
valid_accuracy = accuracy_score(y_valid, valid_predictions)
print(f'Validation Accuracy: {valid_accuracy}')
print(classification_report(y_valid, valid_predictions))
print(confusion_matrix(y_valid, valid_predictions))

from tensorflow.keras.applications import ResNet50
from sklearn.ensemble import RandomForestClassifier
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Extract features using VGG19
train_features = base_model.predict(x_train)
val_features = base_model.predict(x_val)

# Flatten or reshape the features
train_features_flat = train_features.reshape(train_features.shape[0], -1)
val_features_flat = val_features.reshape(val_features.shape[0], -1)

# Train Random Forest classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(train_features_flat, y_train)

# Predict on validation set
val_predictions = clf.predict(val_features_flat)

# Evaluate the model
val_accuracy = accuracy_score(y_val, val_predictions)
print(f'Validation Accuracy: {val_accuracy}')
print(classification_report(y_val, val_predictions))
print(confusion_matrix(y_val, val_predictions))

valid_features= base_model.predict(x_valid)
valid_features_flat = valid_features.reshape(valid_features.shape[0], -1)
valid_predictions = clf.predict(valid_features_flat)
valid_accuracy = accuracy_score(y_valid, valid_predictions)
print(f'Validation Accuracy: {valid_accuracy}')
print(classification_report(y_valid, valid_predictions))
print(confusion_matrix(y_valid, valid_predictions))

from tensorflow.keras.applications import MobileNetV2
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load MobileNetV2 base model
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Extract features using MobileNetV2
train_features = base_model.predict(x_train)
val_features = base_model.predict(x_val)

# Flatten or reshape the features
train_features_flat = train_features.reshape(train_features.shape[0], -1)
val_features_flat = val_features.reshape(val_features.shape[0], -1)

# Train Random Forest classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(train_features_flat, y_train)

# Predict on validation set
val_predictions = clf.predict(val_features_flat)

# Evaluate the model
val_accuracy = accuracy_score(y_val, val_predictions)
print(f'Validation Accuracy: {val_accuracy}')
print(classification_report(y_val, val_predictions))
print(confusion_matrix(y_val, val_predictions))

model.evaluate(x_valid,y_valid)

from tensorflow.keras.applications import InceptionResNetV2
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load InceptionResNetV2 base model
base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Extract features using InceptionResNetV2
train_features = base_model.predict(x_train)
val_features = base_model.predict(x_val)

# Flatten or reshape the features
train_features_flat = train_features.reshape(train_features.shape[0], -1)
val_features_flat = val_features.reshape(val_features.shape[0], -1)

# Train Random Forest classifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(train_features_flat, y_train)

# Predict on validation set
val_predictions = clf.predict(val_features_flat)

# Evaluate the model
val_accuracy = accuracy_score(y_val, val_predictions)
print(f'Validation Accuracy: {val_accuracy}')
print(classification_report(y_val, val_predictions))
print(confusion_matrix(y_val, val_predictions))

valid_features= base_model.predict(x_valid)
valid_features_flat = valid_features.reshape(valid_features.shape[0], -1)
valid_predictions = clf.predict(valid_features_flat)
valid_accuracy = accuracy_score(y_valid, valid_predictions)
print(f'Validation Accuracy: {valid_accuracy}')
print(classification_report(y_valid, valid_predictions))
print(confusion_matrix(y_valid, valid_predictions))

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input
from tensorflow.keras.applications import VGG19
from tensorflow.keras.optimizers import Adam

# Load VGG19 as the base model
base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the layers of VGG19
for layer in base_model.layers:
    layer.trainable = False

# Add custom layers on top of VGG19
x = base_model.output
x = GlobalAveragePooling2D()(x)  # Convert features to vectors

# A Dense layer to mimic SVM's hyperplane. Note: For binary classification, use 1 unit and for multi-class, use 'n_classes' units
n_classes = len(np.unique(y_train))  # Assuming y_train is your label array
x = Dense(n_classes, activation='linear')(x)  # Linear activation to mimic the SVM hyperplane

# Final model
model = Model(inputs=base_model.input, outputs=x)

# Custom hinge loss for the SVM-like behavior
def hinge_loss(y_true, y_pred):
    return tf.reduce_mean(tf.maximum(1. - y_true * y_pred, 0.))

model.compile(optimizer=Adam(learning_rate=0.0001), loss=hinge_loss, metrics=['accuracy'])

# Convert labels for hinge loss (assumes y_train and y_val are initially in categorical format)
y_train_hinge = 2 * y_train - 1  # Convert labels to -1 or 1
y_val_hinge = 2 * y_val - 1

# Train model
model.fit(x_train, y_train_hinge, batch_size=32, epochs=10, validation_data=(x_val, y_val_hinge))



from tensorflow.keras.applications import Xception, InceptionResNetV2
from tensorflow.keras.layers import Input, Dense, Concatenate
from tensorflow.keras.models import Model
import numpy as np
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Load Xception and InceptionResNetV2 models
xception = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
inception_resnet_v2 = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

def extract_features(model, x_data):
    features = model.predict(x_data, batch_size=32, verbose=1)
    features_flattened = features.reshape((features.shape[0], -1))
    return features_flattened

# Assuming x_train and x_val are your image data loaded and preprocessed as per your code
x_train_xception_features = extract_features(xception, x_train)
x_val_xception_features = extract_features(xception, x_val)

x_train_inception_resnet_v2_features = extract_features(inception_resnet_v2, x_train)
x_val_inception_resnet_v2_features = extract_features(inception_resnet_v2, x_val)

import numpy as np
np.save("/content/drive/MyDrive/aptos 2019/x_train_inception_resnet_v2_features.npy",x_train_inception_resnet_v2_features)
np.save("/content/drive/MyDrive/aptos 2019/x_val_inception_resnet_v2_features.npy",x_val_inception_resnet_v2_features)
np.save("/content/drive/MyDrive/aptos 2019/x_train_xception_features.npy",x_train_xception_features)
np.save("/content/drive/MyDrive/aptos 2019/x_val_xception_features.npy",x_val_xception_features)

x_train_inception_resnet_v2_features=np.load("/content/drive/MyDrive/aptos 2019/x_train_inception_resnet_v2_features.npy")
x_val_inception_resnet_v2_features=np.load("/content/drive/MyDrive/aptos 2019/x_val_inception_resnet_v2_features.npy")
x_train_xception_features=np.load("/content/drive/MyDrive/aptos 2019/x_train_xception_features.npy")
x_val_xception_features=np.load("/content/drive/MyDrive/aptos 2019/x_val_xception_features.npy")

x_valid=np.load("/content/drive/MyDrive/aptos 2019/x_valid.npy")
from tensorflow.keras.applications import Xception, InceptionResNetV2
from tensorflow.keras.layers import Input, Dense, Concatenate
from tensorflow.keras.models import Model
import numpy as np
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Load Xception and InceptionResNetV2 models
xception = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
inception_resnet_v2 = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

def extract_features(model, x_data):
    features = model.predict(x_data, batch_size=32, verbose=1)
    features_flattened = features.reshape((features.shape[0], -1))
    return features_flattened

# Assuming x_train and x_val are your image data loaded and preprocessed as per your code
x_valid_xception_features = extract_features(xception, x_valid)
x_valid_inception_resnet_v2_features = extract_features(inception_resnet_v2, x_valid)

import numpy as np
np.save("/content/drive/MyDrive/aptos 2019/x_valid_xception_features.npy",x_valid_xception_features)
np.save("/content/drive/MyDrive/aptos 2019/x_valid_inception_resnet_v2_features.npy",x_valid_inception_resnet_v2_features)

x_valid_xception_features=np.load("/content/drive/MyDrive/aptos 2019/x_valid_xception_features.npy")
x_valid_inception_resnet_v2_features=np.load("/content/drive/MyDrive/aptos 2019/x_valid_inception_resnet_v2_features.npy")

# Combine features
x_train_combined = np.hstack((x_train_xception_features, x_train_inception_resnet_v2_features))
x_val_combined = np.hstack((x_val_xception_features, x_val_inception_resnet_v2_features))

# Model training
input_shape = x_train_combined.shape[1]
model = Sequential([
    Dense(512, activation='relu', input_shape=(input_shape,)),  # 1st hidden layer
    Dense(256, activation='relu'),  # 2nd hidden layer
    Dense(128, activation='relu'),  # 3rd hidden layer
    Dense(64, activation='relu'),   # 4th hidden layer
    Dense(32, activation='relu'),   # 5th hidden layer
    Dense(5, activation='softmax')  # Output layer
])
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

BATCH_SIZE = 32
history = model.fit(
    x_train_combined, y_train,batch_size=BATCH_SIZE,
    steps_per_epoch=x_train_combined.shape[0] // BATCH_SIZE,
    epochs=20,
    validation_data=(x_val_combined, y_val)
)

x_valid_combined = np.hstack((x_valid_xception_features, x_valid_inception_resnet_v2_features))
model.evaluate(x_valid_combined,y_valid)

from tensorflow.keras.layers import Input, Concatenate, Dense
from tensorflow.keras.models import Model
BATCH_SIZE=32
# Define input layers for VGG19 and ResNet50 features
input_xception = Input(shape=(x_train_xception_features.shape[1],))
input_inception_resnet_v2 = Input(shape=(x_train_inception_resnet_v2_features.shape[1],))

# Define the neural network layers
dense_1 = Dense(512, activation='relu')(input_xception)
dense_2 = Dense(256, activation='relu')(dense_1)
dense_3 = Dense(256, activation='relu')(dense_2)
dense_03 = Dense(128, activation='relu')(dense_3)
# Cross-pooling layer to combine VGG19 and ResNet50 features
cross_pooled = Concatenate()([dense_03, input_inception_resnet_v2])

dense_4 = Dense(128, activation='relu')(cross_pooled)
dense_04 = Dense(64, activation='relu')(dense_4)
dense_5 = Dense(32, activation='relu')(dense_04)
output = Dense(5, activation='softmax')(dense_5)

# Create the model
model = Model(inputs=[input_xception, input_inception_resnet_v2], outputs=output)
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
history = model.fit(
    [x_train_xception_features, x_train_inception_resnet_v2_features], y_train,
    epochs=30,
    validation_data=([x_val_xception_features, x_val_inception_resnet_v2_features], y_val)
)

model.evaluate([x_valid_xception_features, x_valid_inception_resnet_v2_features], y_valid)

from tensorflow.keras.layers import Input, Concatenate, Dense, BatchNormalization, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam

BATCH_SIZE = 32
EPOCHS = 50  # Increasing the number of epochs for more learning

# Define input layers for Xception and Inception-ResNet-v2 features
input_xception = Input(shape=(x_train_xception_features.shape[1],))
input_inception_resnet_v2 = Input(shape=(x_train_inception_resnet_v2_features.shape[1],))

# Define the neural network layers with Batch Normalization and Dropout
dense_1 = Dense(512, activation='relu')(input_xception)
dense_1 = BatchNormalization()(dense_1)  # Added Batch Normalization
dense_1 = Dropout(0.3)(dense_1)  # Added Dropout

dense_2 = Dense(256, activation='relu')(dense_1)
dense_2 = BatchNormalization()(dense_2)
dense_2 = Dropout(0.3)(dense_2)

dense_3 = Dense(256, activation='relu')(dense_2)
dense_3 = BatchNormalization()(dense_3)
dense_3 = Dropout(0.3)(dense_3)

dense_03 = Dense(128, activation='relu')(dense_3)
dense_03 = BatchNormalization()(dense_03)

# Cross-pooling layer to combine Xception and Inception-ResNet-v2 features
cross_pooled = Concatenate()([dense_03, input_inception_resnet_v2])

dense_4 = Dense(128, activation='relu')(cross_pooled)
dense_4 = BatchNormalization()(dense_4)
dense_4 = Dropout(0.3)(dense_4)

dense_04 = Dense(64, activation='relu')(dense_4)
dense_04 = BatchNormalization()(dense_04)

dense_5 = Dense(32, activation='relu')(dense_04)
output = Dense(5, activation='softmax')(dense_5)

# Create the model
model = Model(inputs=[input_xception, input_inception_resnet_v2], outputs=output)

# Compile the model with Adam optimizer and reduced learning rate
optimizer = Adam(learning_rate=0.0001)  # Reduced learning rate
model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])

# Early stopping and learning rate reduction
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)
model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max')

# Train the model with validation and callbacks
history = model.fit(
    [x_train_xception_features, x_train_inception_resnet_v2_features], y_train,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    validation_data=([x_val_xception_features, x_val_inception_resnet_v2_features], y_val),
    callbacks=[early_stopping, reduce_lr, model_checkpoint]
)

from tensorflow.keras.layers import Input, Concatenate, Dense
from tensorflow.keras.models import Model
BATCH_SIZE=32
# Define input layers for VGG19 and ResNet50 features
input_xception = Input(shape=(x_train_xception_features.shape[1],))
input_inception_resnet_v2 = Input(shape=(x_train_inception_resnet_v2_features.shape[1],))

# Define the neural network layers
dense_1 = Dense(512, activation='relu')(input_xception)
dense_2 = Dense(256, activation='relu')(dense_1)
dense_3 = Dense(256, activation='relu')(dense_2)
dense_03 = Dense(128, activation='relu')(dense_3)
# Cross-pooling layer to combine VGG19 and ResNet50 features
cross_pooled = Concatenate()([dense_1, input_inception_resnet_v2])

dense_4 = Dense(128, activation='relu')(cross_pooled)
dense_04 = Dense(64, activation='relu')(dense_4)
dense_5 = Dense(32, activation='relu')(dense_04)
output = Dense(5, activation='softmax')(dense_5)

# Create the model
model = Model(inputs=[input_xception, input_inception_resnet_v2], outputs=output)
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
history = model.fit(
    [x_train_xception_features, x_train_inception_resnet_v2_features], y_train,
    epochs=30,
    validation_data=([x_val_xception_features, x_val_inception_resnet_v2_features], y_val)
)

model.evaluate([x_valid_xception_features, x_valid_inception_resnet_v2_features], y_valid)

!pip install SENet

from tensorflow.keras.applications import NASNetLarge, SEnet

from tensorflow.keras.applications import NASNetLarge, EfficientNetV2S
import numpy as np

# Load NASNetLarge and SENet with pre-trained ImageNet weights
nasnet = NASNetLarge(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
effnet = EfficientNetV2S(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

def extract_features(model, x_data):
    features = model.predict(x_data, batch_size=32, verbose=1)
    features_flattened = features.reshape((features.shape[0], -1))
    return features_flattened

# Assuming 'x_valid' is your validation dataset pre-processed to the required input size (e.g., 331x331 for NASNetLarge)
x_test_nasnet_features = extract_features(nasnet, x_val)
x_test_effnet_features = extract_features(effnet, x_val)
x_valid_nasnet_features = extract_features(nasnet, x_valid)
x_valid_effnet_features = extract_features(effnet, x_valid)
x_train_nasnet_features = extract_features(nasnet, x_train)  # Extract features using NASNetLarge
x_train_effnet_features = extract_features(effnet, x_train)  # Extract features using EfficientNetV2S

import numpy as np
from tensorflow.keras.applications import NASNetLarge, EfficientNetV2S

# Load NASNetLarge and SENet with pre-trained ImageNet weights
nasnet = NASNetLarge(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
effnet = EfficientNetV2S(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

def extract_features(model, x_data):
    features = model.predict(x_data, batch_size=32, verbose=1)
    features_flattened = features.reshape((features.shape[0], -1))
    return features_flattened

# Assuming 'x_train', 'x_valid', and 'x_val' are your datasets
# pre-processed to the required input size (e.g., 224x224)

# Extract features for the training data
x_train_nasnet_features = extract_features(nasnet, x_train)  # Extract features using NASNetLarge
x_train_effnet_features = extract_features(effnet, x_train)  # Extract features using EfficientNetV2S


# You already have the following feature extraction for x_val and x_valid:
x_test_nasnet_features = extract_features(nasnet, x_val)
x_test_effnet_features = extract_features(effnet, x_val)
x_valid_nasnet_features = extract_features(nasnet, x_valid)
x_valid_effnet_features = extract_features(effnet, x_valid)


# Now you can save the features:
np.save("/content/drive/MyDrive/aptos 2019/x_train_nasnet_features.npy", x_train_nasnet_features)
np.save("/content/drive/MyDrive/aptos 2019/x_train_effnet_features.npy", x_train_effnet_features)

import numpy as np
np.save("/content/drive/MyDrive/aptos 2019/x_train_nasnet_features.npy",x_train_nasnet_features)
np.save("/content/drive/MyDrive/aptos 2019/x_train_effnet_features.npy",x_train_effnet_features)

import numpy as np
np.save("/content/drive/MyDrive/aptos 2019/x_test_nasnet_features.npy",x_test_nasnet_features)
np.save("/content/drive/MyDrive/aptos 2019/x_test_effnet_features.npy",x_test_effnet_features)
np.save("/content/drive/MyDrive/aptos 2019/x_valid_nasnet_features.npy",x_valid_nasnet_features)
np.save("/content/drive/MyDrive/aptos 2019/x_valid_effnet_features.npy",x_valid_effnet_features)

x_test_nasnet_features = extract_features(nasnet, x_val)
x_test_effnet_features = extract_features(effnet, x_val)
x_valid_nasnet_features = extract_features(nasnet, x_valid)
x_valid_effnet_features = extract_features(effnet, x_valid)

x_train_nasnet_features=np.load("/content/drive/MyDrive/aptos 2019/x_train_nasnet_features.npy")
x_train_effnet_features=np.load("/content/drive/MyDrive/aptos 2019/x_train_effnet_features.npy")
x_test_nasnet_features=np.load("/content/drive/MyDrive/aptos 2019/x_test_nasnet_features.npy")
x_test_effnet_features=np.load("/content/drive/MyDrive/aptos 2019/x_test_effnet_features.npy")
x_valid_nasnet_features=np.load("/content/drive/MyDrive/aptos 2019/x_valid_nasnet_features.npy")
x_valid_effnet_features=np.load("/content/drive/MyDrive/aptos 2019/x_valid_effnet_features.npy")